{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook to find cyanobacterial opsins similar to GR\n",
        "\n",
        "This notebook submits a **BLASTP** job to the EMBL‑EBI web service against **UniRef90**, poll for completion, parse the tabular results, and fetch the top hits as FASTA sequences. It uses GR opsin as bait."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Packages imported — ready!\n"
          ]
        }
      ],
      "source": [
        "import requests, time, os\n",
        "from pathlib import Path\n",
        "from Bio import SeqIO\n",
        "import re\n",
        "\n",
        "print('Packages imported — ready!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper functions for the BLAST workflow\n",
        "def submit_blast(sequence, email, db='uniref90', program='blastp'):\n",
        "    url = 'https://www.ebi.ac.uk/Tools/services/rest/ncbiblast/run'\n",
        "    clean_seq = sequence.replace(\"\\n\", \"\").replace(\"*\", \"\").strip()\n",
        "    data = {\n",
        "        'email': email,\n",
        "        'sequence': clean_seq,\n",
        "        'stype': 'protein',\n",
        "        'database': db,\n",
        "        'program': program,\n",
        "        'alignments': 500,\n",
        "        'exp': 100,\n",
        "        'filter': 'F'\n",
        "    }\n",
        "    response = requests.post(url, data=data)\n",
        "    response.raise_for_status()\n",
        "    return response.text.strip()\n",
        "def get_results(job_id, result_type='out'):\n",
        "    url = f\"https://www.ebi.ac.uk/Tools/services/rest/ncbiblast/result/{job_id}/{result_type}\"\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    return response.text\n",
        "\n",
        "def check_status(job_id: str) -> str:\n",
        "    url = f'https://www.ebi.ac.uk/Tools/services/rest/ncbiblast/status/{job_id}'\n",
        "    r = requests.get(url)\n",
        "    r.raise_for_status()\n",
        "    return r.text.strip()\n",
        "\n",
        "def get_tabular_results(job_id: str):\n",
        "    url = f'https://www.ebi.ac.uk/Tools/services/rest/ncbiblast/result/{job_id}/tab'\n",
        "    r = requests.get(url)\n",
        "    if r.status_code == 400:\n",
        "        return None  # likely no hits\n",
        "    r.raise_for_status()\n",
        "    return r.text\n",
        "\n",
        "\n",
        "def parse_uniref_ids_from_out(text_result, max_hits=200):\n",
        "    cluster_ids = []\n",
        "    seen = set()\n",
        "    for line in text_result.splitlines():\n",
        "        if line.startswith(\">UR90:UniRef90_\"):\n",
        "            # Only allow IDs with valid protein accessions: typically 6+ alphanum characters\n",
        "            match = re.match(r\">UR90:(UniRef90_[A-Z0-9]{6,})\", line)\n",
        "            if match:\n",
        "                uid = match.group(1)\n",
        "                if uid not in seen:\n",
        "                    cluster_ids.append(uid)\n",
        "                    seen.add(uid)\n",
        "        if len(cluster_ids) >= max_hits:\n",
        "            break\n",
        "    return cluster_ids\n",
        "\n",
        "def fetch_fasta(uid):\n",
        "    url = f'https://rest.uniprot.org/uniref/{uid}.fasta'\n",
        "    r = requests.get(url)\n",
        "    if r.status_code == 404:\n",
        "        print(f\"⚠️  Skipping invalid UniRef cluster ID: {uid}\")\n",
        "        return None\n",
        "    r.raise_for_status()\n",
        "    return r.text\n",
        "\n",
        "\n",
        "def write_fasta(seqs, out_path):\n",
        "    with open(out_path, 'w') as fh:\n",
        "        for s in seqs:\n",
        "            fh.write(s)\n",
        "    print(f'Wrote {len(seqs)} sequences to {out_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output directory: /Users/oakley/Documents/GitHub/cyano_rhodopsins/blast_notebook_results\n"
          ]
        }
      ],
      "source": [
        "# Parameters — edit these!\n",
        "email = 'oakley@ucsb.edu'   # required by EBI\n",
        "input_fasta = 'GR.fasta'               # path to your query FASTA file\n",
        "max_hits = 150                         # number of UniRef90 hits to keep\n",
        "\n",
        "out_dir = Path('blast_notebook_results')\n",
        "out_dir.mkdir(exist_ok=True)\n",
        "print(f'Output directory: {out_dir.resolve()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submitting BLAST for: BAC88139.1  (length 298 aa)\n",
            "Job ID: ncbiblast-R20250619-013645-0617-23440871-p1m\n",
            "[17:36:49] status: RUNNING\n",
            "[17:36:56] status: RUNNING\n",
            "[17:37:03] status: RUNNING\n",
            "[17:37:10] status: RUNNING\n",
            "[17:37:17] status: RUNNING\n",
            "[17:37:24] status: RUNNING\n",
            "[17:37:31] status: RUNNING\n",
            "[17:37:39] status: RUNNING\n",
            "[17:37:45] status: RUNNING\n",
            "[17:37:52] status: RUNNING\n",
            "[17:37:59] status: RUNNING\n",
            "[17:38:07] status: RUNNING\n",
            "[17:38:14] status: RUNNING\n",
            "[17:38:23] status: RUNNING\n",
            "[17:38:30] status: RUNNING\n",
            "[17:38:37] status: RUNNING\n",
            "[17:38:44] status: RUNNING\n",
            "[17:38:51] status: RUNNING\n",
            "[17:38:58] status: RUNNING\n",
            "[17:39:05] status: RUNNING\n",
            "[17:39:12] status: RUNNING\n",
            "[17:39:19] status: RUNNING\n",
            "[17:39:27] status: RUNNING\n",
            "[17:39:34] status: RUNNING\n",
            "[17:39:41] status: RUNNING\n",
            "[17:39:48] status: RUNNING\n",
            "[17:39:55] status: RUNNING\n",
            "[17:40:02] status: RUNNING\n",
            "[17:40:09] status: RUNNING\n",
            "[17:40:17] status: RUNNING\n",
            "[17:40:24] status: RUNNING\n",
            "[17:40:31] status: RUNNING\n",
            "[17:40:38] status: RUNNING\n",
            "[17:40:45] status: RUNNING\n",
            "[17:40:52] status: RUNNING\n",
            "[17:40:59] status: RUNNING\n",
            "[17:41:06] status: RUNNING\n",
            "[17:41:13] status: RUNNING\n",
            "[17:41:20] status: RUNNING\n",
            "[17:41:27] status: RUNNING\n",
            "[17:41:34] status: RUNNING\n",
            "[17:41:41] status: RUNNING\n",
            "[17:41:48] status: RUNNING\n",
            "[17:41:55] status: RUNNING\n",
            "[17:42:02] status: RUNNING\n",
            "[17:42:09] status: RUNNING\n",
            "[17:42:16] status: RUNNING\n",
            "[17:42:23] status: RUNNING\n",
            "[17:42:30] status: RUNNING\n",
            "[17:42:37] status: RUNNING\n",
            "[17:42:44] status: RUNNING\n",
            "[17:42:51] status: RUNNING\n",
            "[17:42:58] status: RUNNING\n",
            "[17:43:05] status: RUNNING\n",
            "[17:43:13] status: FINISHED\n",
            "BLASTP 2.16.0+\n",
            "\n",
            "\n",
            "Reference: Stephen F. Altschul, Thomas L. Madden, Alejandro A.\n",
            "Schaffer, Jinghui Zhang, Zheng Zhang, Webb Miller, and David J.\n",
            "Lipman (1997), \"Gapped BLAST and PSI-BLAST: a new generation of\n",
            "protein database search programs\", Nucleic Acids Res. 25:3389-3402.\n",
            "\n",
            "\n",
            "Reference for composition-based statistics: Alejandro A. Schaffer,\n",
            "L. Aravind, Thomas L. Madden, Sergei Shavirin, John L. Spouge, Yuri\n",
            "I. Wolf, Eugene V. Koonin, and Stephen F. Altschul (2001),\n",
            "\"Improving the accuracy of PSI-BLAST protein database searches with\n",
            "composition-based statistics and other refinements\", Nucleic Acids\n",
            "Res. 29:2994-3005.\n",
            "\n",
            "\n",
            "\n",
            "Database: uniref90\n",
            "           199,553,294 sequences; 68,521,788,531 total letters\n",
            "\n",
            "\n",
            "\n",
            "Query= EMBOSS_001\n",
            "\n",
            "Length=298\n",
            "                                                                      Score     E\n",
            "Sequences producing significant alignments:                          (Bits)  Value\n",
            "\n",
            "UR90:UniRef90_Q7NP59 Gll0198 protein n=1 Tax=Gloeobacter violaceus...  573     0.0\n",
            "UR90:Un\n",
            "Full BLAST output saved ➜  blast_notebook_results/BAC88139.1_uniref90.blast.out\n"
          ]
        }
      ],
      "source": [
        "# --- BLASTP against UniRef90: run, poll, and save raw text output ---\n",
        "\n",
        "record = next(SeqIO.parse(input_fasta, \"fasta\"))\n",
        "print(f\"Submitting BLAST for: {record.id}  (length {len(record.seq)} aa)\")\n",
        "\n",
        "job_id = submit_blast(str(record.seq), email)   # uses the helper in earlier cell\n",
        "print(\"Job ID:\", job_id)\n",
        "\n",
        "# Poll until finished\n",
        "while True:\n",
        "    status = check_status(job_id)               # helper\n",
        "    print(f\"[{time.strftime('%H:%M:%S')}] status: {status}\")\n",
        "    if status == \"FINISHED\":\n",
        "        break\n",
        "    elif status == \"ERROR\":\n",
        "        raise RuntimeError(\"BLAST job failed\")\n",
        "    time.sleep(5)\n",
        "\n",
        "# Retrieve raw BLAST text output\n",
        "text_result = get_results(job_id, result_type=\"out\")  # plain text\n",
        "print(text_result[:1000])  # preview first 1 000 chars\n",
        "\n",
        "# Save to disk for later parsing\n",
        "blast_txt_path = out_dir / f\"{record.id}_uniref90.blast.out\"\n",
        "blast_txt_path.write_text(text_result)\n",
        "print(f\"Full BLAST output saved ➜  {blast_txt_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "aeb01251",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150 UniRef IDs retrieved\n",
            "⚠️  Skipping invalid UniRef cluster ID: UniRef90_A0A0Q4FQD5\n",
            "⚠️  Skipping invalid UniRef cluster ID: UniRef90_A0A6J7GMR2\n",
            "⚠️  Skipping invalid UniRef cluster ID: UniRef90_A0A0J6VIK5\n",
            "⚠️  Skipping invalid UniRef cluster ID: UniRef90_UPI001A1BE314\n",
            "Wrote 146 sequences to blast_notebook_results/BAC88139.1_top150_uniref90.fasta\n",
            "FASTA file written ➜  blast_notebook_results/BAC88139.1_top150_uniref90.fasta\n"
          ]
        }
      ],
      "source": [
        "# --- Parse saved BLAST output and fetch top UniRef90 FASTA sequences ---\n",
        "\n",
        "max_hits = 150                             # Or set as needed\n",
        "text_result = blast_txt_path.read_text()   # Load saved output\n",
        "\n",
        "uids = parse_uniref_ids_from_out(text_result, max_hits)  # Parse UniRef cluster IDs\n",
        "print(f\"{len(uids)} UniRef IDs retrieved\")\n",
        "\n",
        "if uids:\n",
        "    seqs = []\n",
        "    for uid in uids:\n",
        "        seq = fetch_fasta(uid)             # Returns None on 404\n",
        "        if seq:\n",
        "            seqs.append(seq)\n",
        "\n",
        "    if seqs:\n",
        "        out_fasta = out_dir / f\"{record.id}_top{max_hits}_uniref90.fasta\"\n",
        "        write_fasta(seqs, out_fasta)       # Save valid FASTA sequences\n",
        "        print(f\"FASTA file written ➜  {out_fasta}\")\n",
        "    else:\n",
        "        print(\"All UniRef IDs failed to fetch. No FASTA file written.\")\n",
        "else:\n",
        "    print(\"No UniRef IDs found. Nothing to download.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7265ee3b",
      "metadata": {},
      "source": [
        "# Next Run MAFFT on all the sequences to align"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "edbe1984",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running MAFFT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "outputhat23=2\n",
            "treein = 0\n",
            "compacttree = 0\n",
            "stacksize: 8192 kb\n",
            "rescale = 1\n",
            "All-to-all alignment.\n",
            "tbfast-pair (aa) Version 7.525\n",
            "alg=L, model=BLOSUM62, 2.00, -0.10, +0.10, noshift, amax=0.0\n",
            "0 thread(s)\n",
            "\n",
            "outputhat23=2\n",
            "Loading 'hat3.seed' ... \n",
            "done.\n",
            "Writing hat3 for iterative refinement\n",
            "rescale = 1\n",
            "Gap Penalty = -1.53, +0.00, +0.00\n",
            "tbutree = 1, compacttree = 0\n",
            "Constructing a UPGMA tree ... \n",
            "  140 / 146\n",
            "done.\n",
            "\n",
            "Progressive alignment ... \n",
            "STEP   143 /145 \n",
            "Reallocating..done. *alloclen = 1816\n",
            "STEP   145 /145 \n",
            "done.\n",
            "tbfast (aa) Version 7.525\n",
            "alg=A, model=BLOSUM62, 1.53, -0.00, -0.00, noshift, amax=0.0\n",
            "1 thread(s)\n",
            "\n",
            "minimumweight = 0.000010\n",
            "autosubalignment = 0.000000\n",
            "nthread = 0\n",
            "randomseed = 0\n",
            "blosum 62 / kimura 200\n",
            "poffset = 0\n",
            "niter = 2\n",
            "sueff_global = 0.100000\n",
            "nadd = 2\n",
            "Loading 'hat3' ... done.\n",
            "rescale = 1\n",
            "\n",
            "  140 / 146\n",
            "Segment   1/  1    1- 483\n",
            "done 002-001-1  identical.    identical.    identical.    rejected. identical.    rejected. rejected. identical.    identical.    identical.    identical.    identical.   \n",
            "dvtditr (aa) Version 7.525\n",
            "alg=A, model=BLOSUM62, 1.53, -0.00, -0.00, noshift, amax=0.0\n",
            "0 thread(s)\n",
            "\n",
            "\n",
            "Strategy:\n",
            " L-INS-i (Probably most accurate, very slow)\n",
            " Iterative refinement method (<2) with LOCAL pairwise alignment information\n",
            "\n",
            "If unsure which option to use, try 'mafft --auto input > output'.\n",
            "For more information, see 'mafft --help', 'mafft --man' and the mafft page.\n",
            "\n",
            "The default gap scoring scheme has been changed in version 7.110 (2013 Oct).\n",
            "It tends to insert more gaps into gap-rich regions than previous versions.\n",
            "To disable this change, add the --leavegappyregion option.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alignment saved to: blast_notebook_results/BAC88139.1_top150_uniref90.mafft.fasta\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "# Input: FASTA of UniRef sequences\n",
        "fasta_in = Path(\"blast_notebook_results/BAC88139.1_top150_uniref90.fasta\")                           # from previous step\n",
        "msa_out = fasta_in.with_suffix(\".mafft.fasta\")  # output file\n",
        "\n",
        "# Run MAFFT\n",
        "cmd = [\"mafft\", \"--auto\", str(fasta_in)]\n",
        "print(\"Running MAFFT...\")\n",
        "\n",
        "with open(msa_out, \"w\") as outfile:\n",
        "    subprocess.run(cmd, check=True, stdout=outfile)\n",
        "\n",
        "print(f\"Alignment saved to: {msa_out}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "159d5262",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alignment length: 467\n",
            "Number of sequences: 146\n",
            "UniRef90_Q7NP59           M------------------------------------------------------------------LMTVFSSAPELALLGSTFAQVD-------PSNL\n",
            "UniRef90_A0A969T0G4       --------------------------------------------------------------------MIEVSLAPDFTLLGALFVRGD------IADRL\n",
            "UniRef90_A0A2W7ARY7       ----------------------------------------------------------------------MISSMPDFALLGSLVDQGD------VLDRL\n",
            "UniRef90_A0A969FEC7       ---------------------------------------------------------------------MSAILLPDLSLLGAV-AQDD------LLDRL\n",
            "UniRef90_A0A925M2S9       --------------------------------------------------------------------MFDLSPIPDFALLGALLVQDD------SSQRL\n",
            "UniRef90_UPI000A475A3D    --------------------------------------------------------------------MLVISLVPDGTLLGAL-TTGD------MSDRL\n",
            "UniRef90_UPI0035946169    MTTIEDSAFFRKLNLQAILSSVVGTFIFFYSIAQFQISHGFNLQQDSSTNVNGSSCRFKPNPPEQILLMIAVSFISDFPLLGAVLATDD------LPSRV\n",
            "UniRef90_UPI003592F9D2    MET---------------------------------------------------------------KLMILASSLSDFALLG--LLNED------TSSRL\n",
            "UniRef90_UPI0035935AE6    ----------------------------------------------------------------------------------------------------\n",
            "UniRef90_U9W0I1           ---------------------------------------------------------------------------------------ML------TTPLA\n"
          ]
        }
      ],
      "source": [
        "from Bio import AlignIO\n",
        "\n",
        "msa_path = \"blast_notebook_results/BAC88139.1_top150_uniref90.mafft.fasta\"\n",
        "alignment = AlignIO.read(msa_path, \"fasta\")\n",
        "\n",
        "print(f\"Alignment length: {alignment.get_alignment_length()}\")\n",
        "print(f\"Number of sequences: {len(alignment)}\")\n",
        "\n",
        "# Preview first 10 aligned sequences (trimmed to 100 columns)\n",
        "for record in alignment[:10]:\n",
        "    print(f\"{record.id[:25]:25} {record.seq[:100]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f9c91c53",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BAC88139.1_top150_uniref90.fasta\n",
            "BAC88139.1_top150_uniref90.mafft.fasta\n",
            "BAC88139.1_uniref90.blast.out\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(\"\\n\".join(os.listdir(\"blast_notebook_results\")))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "uniref_blast",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
